---
layout: post
title: 23年10月日报
subtitle: 与老师battle的一个月
tags: [2023日报]
comments: true
author: zyk
cover-img: /assets/img/path.jpg
thumbnail-img: /assets/img/duck.png
---

#### 10.6

1.L2正则化项通常不加到loss函数中，而是直接在定义optimizer时候指定weight_decay参数，因为两者等价，并且可以减少计算loss以及反向传播的计算量。

而L1正则化项不能通过optimizer定义，需要加到loss中

2.L2正则化==权重衰减(weight decay)

#### 10.7

1.tensorboard打开网站后没有图像，显示没有画任何数据。可能是输入tensorboard --logdir=。。。时候的路径有问题，退回到记录数据的上一级目录即可

2.我发现ddpg中计算critic的td误差时，q_now用的是经验回放中存储的action，这个action是加了噪声的，而计算q_target是将target_actor直接的输出的action没加噪声的

3.在不同的py文件往一个tensorboard上画时候报错：E1007 22:13:09.027264 25924 directory_watcher.py:254] File runs\experiment_1\events.out.tfevents.1696687683.zyk8p.2144.0 updated even though the current file is runs\experiment_1\events.out.tfevents.1696687683.zyk8p.2144.1

将画图的步骤放在一个文件中不再报错

#### 10.8

1.评测指标MAP（mean average precision）：

首先计算AP：
$$
AP=\frac{1}{Rel}\sum_{k=1}^nP(k)*rel(k)
$$
P(k)是在前k个推荐结果中相关项的比例，rel(k)是个指示函数，当第k个结果是相关项时为1，否则为0。Rel是结果的相关项总数，n是推荐结果的数量
$$
MAP=\frac{1}{Q}\sum_{q=1}^QAP_q
$$
Q是查询（或用户）的总数，AP是第q个用户的AP

2.<实验记录>

[my_original]: ../实验记录/my/original.md

#### 10.12

1.dfs递归题目有两种类型，一个是递到树的某一位置或者到底部时候计算一个全局的指标，另一个是在归的过程中把指标一层一层return回去

2.用gpu将my项目original跑了，变快非常多，但模型训练极其不稳定

3.由于推荐里done信号也是人为加上的，尝试了下在agent计算q_target时候将done信号去掉，结果episode_reward根本跑不上去。又跑了几次，没有done信号真不行。但是好像在测试集上的指标还行啊

#### 10.17

1.chardet库可以检测出文件的编码方式

#### 10.21

1.tqdm用法：

（1）自动更新：

将迭代对象包裹在tqdm()中即可，每次迭代，进度条都会自动更新  for i in tqdm(range(100)):

（2）手动更新：

```python
#手动更新常用with关键字
with tqdm(total=10) as pbar:
    for i in range(10):
        time.sleep(0.5)
        # 更新进度
        pbar.update(1)
        # 在进度条后面添加或修改后缀信息
        pbar.set_postfix(stage=f"step {i+1}", current_value=i**2)
```

注意只有手动更新时候用set_postfix才很方便

#### 10.22

1.模型可视化主要有：

(1)直接print模型：这种如果某一层的输入输出没有对上不会报错

(2)torchsummary：可以在终端输出模型的各个层，各个层输入输出不匹配会报错，但这种对于模型如果有多个输入的情况不友好

(3)tensorboard：利用add_graph函数，可以处理多个输入的情况

2.运行一个py文件时，os.getcwd()返回当前工作目录，这是启动脚本的地方，而不是被调用的脚本文件的位置。也就是，如果一个py文件调用了另一个py文件中的函数，两者的当前路径是一样的，所以导致了找某文件的时候，ctrl+左键可以找到，但是用路径找却找不到的情况

3.在online测试的时候，对于同一个用户在liked_items不同的情况下，推荐的结果都一样，思考后感觉是因为：在训练时候得到的r相当于只与uid有关，所以会对同一user推荐相同的item因为agent认为这些item这个user会喜欢，并没有考虑user此时的状态。debug后发现同一user在不同状态下得到的state_embed不一样，但是action_embed非常相近，导致推荐的物品都一样：

![Snipaste_2023-10-17_16-53-15](\TyporaPicture\23.10记录\Snipaste_2023-10-17_16-53-15.png)

应该是actor网络的第一层和state_embed中的item_embed的连接的权重都被训得非常小了

#### 10.23

1.log没有下标通常为ln而不是$log_{10}$

#### 10.26

1.判断一个点是否在多边形内部：射线法，从该点发射一条水平射线，统计与多边形边界的交点数，如果交点为奇数，点在多边形内；若为偶数，点在多边形外。为确保交点有效，我们检查线段是否跨越射线并确保交点在该点的右侧

#### 10.27

1.把写好的md文件同步到个人网站步骤：

（1）复制TyporaPicture文件夹到myblog1文件夹中

（2）复制要post的md文件到对应路径

（3）把要post的md文件名前加要在什么时间post，如果是此时的时间后，则不会立即post出去  md文件前面加一些yaml信息

（4）修改md文件中的图片路径，将D：这两个字符删除即可

（5）把myblog1 push到waibibabou.github.io仓库即可

#### 10.28

1.SortedList中add() remove() pop() bisect_left() count() index()都是$O(logn)$

2.$gcd(x,y)=gcd(x−y,y)$

3.图上dfs使用visited数组(或set)避免重复访问，而不是树上dfs使用的(pos,fa)（其实这种方式也可以用visited代替，只不过加一个fa方便），因为图上有环，可能从不同的fa访问到同一个pos

#### 10.29

1.记忆化搜索中的参数的设定是根据已经走过的位置得来的，并且同时是对未走过的位置要求的

2.从维护单调性的角度上来说，单调队列和单调栈是一样的，一个弹出队尾元素，另一个弹出栈顶元素。在单调栈的基础上，单调队列只不过多了一个移除队首过期元素的操作。

#### 10.30

1.pycharm中右键运行时，可能看到Run Python test in 而不是Run 意味着pycharm识别到了文件中的一些测试代码，检查一下文件名和函数名，不要用“test”或者“test”作为前后缀

2.往github上push用香港的节点好，用gpt用台湾的节点



leetcode 2893  1124  codefun 81  total  1205
