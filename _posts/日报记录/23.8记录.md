##### 8.13

1.ValueError: Exceeds the limit (4300) for integer string conversion; use sys.set_int_max_str_digits() to increase the limit。设置sys.set_int_max_str_digits(100000)即可

2.python中pow(,,mod)实现快速幂，虽然python中不需要考虑int的溢出问题，但是在运算过程中先mod而不是到最后mod会大大提高运算速度

3.max()如果传入大于一个参数，则返回这些参数中的最大值，如果只传入一个参数，则该参数必须可迭代，返回该参数中的最大值

##### 8.16

1.python中在进行浮点运算时，可能由于精度问题导致结果不准确，如果对数据精度有要求，可以用Decimal类，实例化时传入整数或者字符串，如果传入float会导致结果不准确（float本身就存在精度问题），之后可以像基本数据类型一样进行运算

##### 8.17

1.list.copy()与copy.copy()为浅拷贝，如果有多层嵌套需要用copy.deepcopy()深拷贝

2.python中的闭包函数可以使用外面的变量，但是如果要对其做出改变（list.append之类的没有改变地址的不算），需要nonlocal关键字

3.with关键字工作原理：

(1)紧跟with后面的语句被求值后，返回对象的“\_\_enter\_\_()”方法被调用，这个方法的返回值将被赋值给as后面的变量，如果没有as就不赋值了

(2)当with后面的代码块全部被执行完之后，将调用前面返回对象的“\_\_exit\_\_()”方法。

4.python字符串、list之类的切片操作时间复杂度为O(k) 正比于切出来的数量，但是切片操作太牛了导致很多n=10**5的通过切片可以用n^2的复杂度通过

##### 8.18

1.再看了DRGR的代码，改了其中attention的部分，因为之前维度有问题，attention的softmax后权重都是1，改了之后跑一直没有跑上去

##### 8.19

1.<实验记录>DRGR在改了attention维度基础上又加了网络权重初始化操作，就能跑上去了

[DRGR]: ../实验记录/5.md

##### 8.22

1.在import torch时候报错：OSError: [WinError 1455] 页面文件太小,无法完成操作。是因为内存不足，清除部分内存即可

2.用户变量和系统变量的优先级：

（1）普通变量：如果在用户变量和系统变量中创建同名变量，那么用户变量会覆盖系统变量，用户环境变量优先级高于系统环境变量

（2）Path变量：对于 Path 变量，系统环境变量优先级高于用户环境变量

##### 8.24

1.<实验记录>在DRGR代码中在概率为0时主动加一个很小的数依然后续报错概率为0，分析后可能因为概率是一个非常接近0的数而不是0，导致没有加上很小的数，改后不再报错

[DRGR]: ../实验记录/6.md

##### 8.29

1.在单向链表中，头结点为空，尾节点正常存储值。但在lru题目中需要的双向链表中，由于需要改next节点的pre，所以将尾节点也设为空，防止next出现none情况，这样方便写代码，否则需要额外判断是否为none

##### 8.30

1.tensor的.T与.t()相同都是只能对一个二维tensor做转置，如果要对>=3维的tensor转置用.transpose(dim1,dim2)

##### 8.31

1.<代码块>ndcg指标计算：

[ndcg]: ../代码块/ndcg.md

$DCG_p=\sum_{i=1}^p\frac{rel_i}{log_2(i+1)}$或者有一种更常用的公式$DCG_p=\sum^p_{i=1}\frac{2^{rel_i}-1}{log_2(i+1)}$，其中rel为relative缩写，表示物品相关性，当相关性只有0或1时，即$rel_i\in\{0,1\}$上面两个公式等价。

$IDCG_p=\sum_{i=1}^{|REL_p|}\frac{2^{rel_i}-1}{log_2(i+1)}$其中$REL_p$将推荐结果按照相关性从大到小排序，而不是数据库中的最好的k个物品

ndcg是召回率recall的补充，因为recall没有考虑推荐结果的顺序，而ndcg考虑顺序，所以这两个指标一般同时出现

2.<实验记录>via那份代码

[via]: ../实验记录/via_1.md

该次实验结果与readme.md中结果一致

该代码将embedding进行pretrain并在后续训练中固定，在后续的额外实验中，第一种用concat代替embedding网络中的dot操作，效果变差；第二种用评分值代替学习使用的label值方法，效果变好了一点，ndcg@10从0.39提高到0.42。后续又尝试了加入per，几乎没有提升

代码中存在的问题，对于训练集测试集划分方式是对用户划分，而不是对于用户的记录划分。然而在训练embedding时候，用到了所有评分数据进行训练，测试数据提前泄露了，github中有人指出了该问题。user_movie_embedding_case4.h5不知道如何生成的。

lc 2643 1034   codefun 74  total 1108